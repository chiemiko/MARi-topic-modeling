{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import nltk.corpus\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import re\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data_processed/concatenated_data_cleaned_labeled.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['not', 'are', 'has', \"wasn't\", \"doesn't\", 'did', 'on', 'his', 'hasn', 'with', 'there', 're', 'if', 'both', 'too', \"didn't\", \"she's\", 'mightn', 'being', 'through', 'other', 'against', 'ain', 'herself', 'now', 'am', 'it', 'why', 't', 'don', 'no', 'our', 'doesn', 'their', 'down', 'shan', 'wasn', 'yourselves', 'were', 'd', 'o', 'doing', \"hadn't\", \"it's\", \"you've\", 'its', 'him', 'under', \"you're\", 'you', 'over', 'whom', 'so', 'off', 'up', 'what', 'to', 'she', \"hasn't\", 'some', 'from', 'of', 'out', \"shouldn't\", 'yours', 'weren', 'further', 'these', 'each', 'which', 'such', 'here', 'below', 'himself', 'had', \"you'll\", 'an', \"needn't\", 'or', 'yourself', 'own', 'ma', 'after', 'those', 'couldn', 'into', 'this', 'isn', 'themselves', 'when', 've', 'just', 'most', 's', \"you'd\", 'me', 'them', 'been', 'at', 'should', \"aren't\", 'shouldn', 'by', 'above', 'the', 'because', 'will', \"wouldn't\", 'where', 'i', 'hers', 'then', 'your', \"weren't\", \"haven't\", 'as', 'didn', 'he', 'y', 'theirs', 'and', 'very', 'was', 'nor', 'all', \"that'll\", 'for', 'be', 'few', \"should've\", \"couldn't\", 'can', \"mustn't\", 'until', 'her', 'does', \"don't\", 'mustn', 'have', 'but', 'they', 'hadn', 'll', 'having', 'won', 'how', 'aren', \"shan't\", 'ourselves', 'between', 'more', 'is', 'm', 'that', 'who', \"won't\", 'before', 'in', 'than', 'needn', 'about', 'while', 'myself', 'we', 'any', \"isn't\", 'same', 'haven', 'wouldn', 'my', 'only', 'once', 'during', \"mightn't\", 'itself', 'do', 'ours', 'again', 'a', 'full', 'time', 'job', 'type', 'skills', 'ability', 'equal', 'opportunity', 'employer', 'years', 'experience', 'at', 'least', 'you', 'vacation', 'generous', 'benefits', 'work', 'working', 'worked', 'role', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', 'overview', 'responsibilities', 'company', 'requirements', 'required', 'use', 'able', 'national', 'origin', 'gender', 'identity', 'citizen', 'perks', 'religion', 'sex', 'without', 'regard', 'color', 'race', 'employment', 'employed', 'class', 'jobsectionheader', 'sexual', 'orientation', 'qualified', 'applicant', 'veteran', 'status', 'individual', 'disability', 'united', 'states', 'capitol', 'one', 'ulta', 'beauty', 'lexisnexis', 'zillow']\n"
     ]
    }
   ],
   "source": [
    "stop_words = list(set(stopwords.words('english')))\n",
    "additional_stop_words = ['full', 'time', 'job', 'type', 'skills', 'ability',\n",
    "                         'equal', 'opportunity', 'employer', 'years', 'experience',\n",
    "                         'at', 'least', 'you', 'vacation', 'generous', 'benefits',\n",
    "                         'work', 'working', 'worked', 'role', '1', '2', '3', '4', '5',\n",
    "                         '6', '7', '8', '9', '10', 'overview', 'responsibilities', 'company',\n",
    "                         'requirements', 'required', 'use', 'able', 'national', 'origin',\n",
    "                         'gender', 'identity', 'citizen', 'perks', 'religion', 'sex',\n",
    "                         'without', 'regard', 'color', 'race', 'employment', 'employed',\n",
    "                         'class', 'jobsectionheader', 'sexual', 'orientation', 'qualified',\n",
    "                         'applicant', 'veteran', 'status', 'individual', 'disability',\n",
    "                         'united', 'states', 'capitol', 'one', 'ulta', 'beauty', 'lexisnexis', 'zillow']\n",
    "stop_words = stop_words + additional_stop_words\n",
    "print(stop_words)\n",
    "\n",
    "def tokenize_filter_desc(description):\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    word_tokens = tokenizer.tokenize(description)\n",
    "    lem = WordNetLemmatizer()\n",
    "    filtered_tokens = []\n",
    "    for w in word_tokens:\n",
    "        if not w.lower() in stop_words:\n",
    "            filtered_tokens.append(lem.lemmatize(w.lower()))\n",
    "    return filtered_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "desc_tokens = []\n",
    "new_desc = []\n",
    "\n",
    "for index, row in df.iterrows():    \n",
    "    tokens = tokenize_filter_desc(row['description'])\n",
    "    desc_tokens.append(tokens)\n",
    "    new_desc.append(' '.join(tokens))\n",
    "\n",
    "df['desc_tokens'] = desc_tokens\n",
    "df['new_description'] = new_desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bin_role</th>\n",
       "      <th>company</th>\n",
       "      <th>description</th>\n",
       "      <th>location</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>desc_tokens</th>\n",
       "      <th>new_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Noom Inc.</td>\n",
       "      <td>At Noom, we use scientifically proven methods...</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>https://www.indeed.com/pagead/clk?mo=r&amp;ad=-6NY...</td>\n",
       "      <td>[noom, scientifically, proven, method, help, u...</td>\n",
       "      <td>noom scientifically proven method help user cr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Strategic Financial Solutions</td>\n",
       "      <td>Overview\\nDo you love numbers and finding the...</td>\n",
       "      <td>New York, NY 10018</td>\n",
       "      <td>Lead Data Scientist</td>\n",
       "      <td>https://www.indeed.com/pagead/clk?mo=r&amp;ad=-6NY...</td>\n",
       "      <td>[love, number, finding, story, number, thought...</td>\n",
       "      <td>love number finding story number thought tackl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Averity</td>\n",
       "      <td>We are one of the world's premiere travel tec...</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>Manager, Data Science</td>\n",
       "      <td>https://www.indeed.com/pagead/clk?mo=r&amp;ad=-6NY...</td>\n",
       "      <td>[world, premiere, travel, technology, company,...</td>\n",
       "      <td>world premiere travel technology company hirin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Lenmar Consulting</td>\n",
       "      <td>Medical Data Scientist Must have at least 2 y...</td>\n",
       "      <td>Woodcliff Lake, NJ</td>\n",
       "      <td>Medical Data Scientist</td>\n",
       "      <td>https://www.indeed.com/pagead/clk?mo=r&amp;ad=-6NY...</td>\n",
       "      <td>[medical, data, scientist, must, clinical, dat...</td>\n",
       "      <td>medical data scientist must clinical data revi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Memorial Sloan Kettering</td>\n",
       "      <td>Company Overview\\nAt Memorial Sloan Kettering...</td>\n",
       "      <td>New York, NY 10017</td>\n",
       "      <td>Sr Strategic Consultant / Data Scientist (Pati...</td>\n",
       "      <td>https://www.indeed.com/pagead/clk?mo=r&amp;ad=-6NY...</td>\n",
       "      <td>[memorial, sloan, kettering, msk, changing, wa...</td>\n",
       "      <td>memorial sloan kettering msk changing way trea...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         bin_role                        company  \\\n",
       "0   Data Engineer                      Noom Inc.   \n",
       "1  Data Scientist  Strategic Financial Solutions   \n",
       "2  Data Scientist                        Averity   \n",
       "3  Data Scientist              Lenmar Consulting   \n",
       "4  Data Scientist       Memorial Sloan Kettering   \n",
       "\n",
       "                                         description            location  \\\n",
       "0   At Noom, we use scientifically proven methods...        New York, NY   \n",
       "1   Overview\\nDo you love numbers and finding the...  New York, NY 10018   \n",
       "2   We are one of the world's premiere travel tec...        New York, NY   \n",
       "3   Medical Data Scientist Must have at least 2 y...  Woodcliff Lake, NJ   \n",
       "4   Company Overview\\nAt Memorial Sloan Kettering...  New York, NY 10017   \n",
       "\n",
       "                                               title  \\\n",
       "0                                     Data Engineer    \n",
       "1                               Lead Data Scientist    \n",
       "2                             Manager, Data Science    \n",
       "3                            Medical Data Scientist    \n",
       "4  Sr Strategic Consultant / Data Scientist (Pati...   \n",
       "\n",
       "                                                 url  \\\n",
       "0  https://www.indeed.com/pagead/clk?mo=r&ad=-6NY...   \n",
       "1  https://www.indeed.com/pagead/clk?mo=r&ad=-6NY...   \n",
       "2  https://www.indeed.com/pagead/clk?mo=r&ad=-6NY...   \n",
       "3  https://www.indeed.com/pagead/clk?mo=r&ad=-6NY...   \n",
       "4  https://www.indeed.com/pagead/clk?mo=r&ad=-6NY...   \n",
       "\n",
       "                                         desc_tokens  \\\n",
       "0  [noom, scientifically, proven, method, help, u...   \n",
       "1  [love, number, finding, story, number, thought...   \n",
       "2  [world, premiere, travel, technology, company,...   \n",
       "3  [medical, data, scientist, must, clinical, dat...   \n",
       "4  [memorial, sloan, kettering, msk, changing, wa...   \n",
       "\n",
       "                                     new_description  \n",
       "0  noom scientifically proven method help user cr...  \n",
       "1  love number finding story number thought tackl...  \n",
       "2  world premiere travel technology company hirin...  \n",
       "3  medical data scientist must clinical data revi...  \n",
       "4  memorial sloan kettering msk changing way trea...  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../data_processed/concatenated_data_cleaned_labeled_preprocessed_alt.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
